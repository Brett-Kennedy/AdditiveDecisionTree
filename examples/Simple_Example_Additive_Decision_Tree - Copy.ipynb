{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7283a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_breast_cancer, load_wine, load_diabetes, make_regression \n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, mean_squared_error\n",
    "\n",
    "# If AdditiveDecisionTree.py is not in the current folder, specify the path \n",
    "import sys  \n",
    "sys.path.insert(0, 'C:\\python_projects\\AdditiveDecisionTree_project\\AdditiveDecisionTree') \n",
    "from AdditiveDecisionTree import AdditiveDecisionTreeClasssifier, AdditiveDecisionTreeRegressor\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74761305",
   "metadata": {},
   "source": [
    "## Methods used to load the toy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80859ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification datasets \n",
    "\n",
    "def get_iris():\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    X = pd.DataFrame(X, columns=iris['feature_names'])\n",
    "    y = pd.Series(y)\n",
    "    return X, y\n",
    "\n",
    "def get_breast_cancer():\n",
    "    X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "    return X, y\n",
    "\n",
    "def get_wine():\n",
    "    X, y = load_wine(return_X_y=True, as_frame=True)\n",
    "    return X, y\n",
    "\n",
    "# Regression datasets\n",
    "\n",
    "def get_diabetes():\n",
    "    data = load_diabetes()\n",
    "    X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "    y = pd.Series(data.target)\n",
    "    return X, y\n",
    "\n",
    "# def get_linnerud():\n",
    "#     data = load_linnerud(as_frame=True)\n",
    "#     X = data.data\n",
    "#     y = data.target['Weight']\n",
    "#     return X,y\n",
    "\n",
    "def get_make_regression():\n",
    "    np.random.seed(0)\n",
    "    X, y = make_regression(noise=0.0)\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.Series(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84fac78",
   "metadata": {},
   "source": [
    "## Example using sklearn's Decision Tree and AddtiveDecisionTree on toy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c2ca6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Note: this provides only an example of using AdditiveDecisionTree and does not \n",
    "# properly test its accuracy. We can, though, see that in terms of test scores,\n",
    "# ADT (Additive Decision Trees) often do about the same as DT (standard Decsion\n",
    "# Trees), but sometimes one or the other does better. \n",
    "# Training scores are also show to give a sense of overfitting.\n",
    "\n",
    "# To estimate complexity for DTs, we use the number of nodes\n",
    "# To estimate complexity for ADTs, we call get_model_complexity(),\n",
    "# which is similar, but considers that additive nodes are more complex.\n",
    "\n",
    "def evaluate_model(clf, clf_desc, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    score_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    score_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "    complexity = 0\n",
    "    if hasattr(clf, \"get_model_complexity\"):\n",
    "        complexity = clf.get_model_complexity()\n",
    "    elif hasattr(clf, \"tree_\"):\n",
    "        complexity = len(clf.tree_.feature)\n",
    "    print(f\"{clf_desc}: Training score: {round(score_train,2)}, Testing score: {round(score_test,2)}, Complexity: {complexity}\")\n",
    "\n",
    "    \n",
    "def evaluate_dataset(dataset_name, X,y):\n",
    "    print(f\"\\n{dataset_name}\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    dt_1 = tree.DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "    evaluate_model(dt_1, \"Standard DT\", X_train, X_test, y_train, y_test)\n",
    "\n",
    "    adt = AdditiveDecisionTreeClasssifier(max_depth=4, allow_additive_nodes=True, verbose_level=0)\n",
    "    evaluate_model(adt, \"Additive DT\", X_train, X_test, y_train, y_test)\n",
    "    return adt\n",
    "    \n",
    "    \n",
    "X,y = get_iris()\n",
    "evaluate_dataset(\"Iris\", X,y)\n",
    "\n",
    "X,y = get_wine()\n",
    "evaluate_dataset(\"Wine\", X,y)\n",
    "\n",
    "X,y = get_breast_cancer()\n",
    "adt = evaluate_dataset(\"Breast Cancer\", X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87babcdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
